{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop \n",
    " <b>  HDFS is also a file system. Core system supports to create directories and files, which you can able to move,copy,rename and delte,process whenever is required. </b>\n",
    "  \n",
    " * HDFS is not a simple file system. It is designed to provide some special features to store and process large data.\n",
    " \n",
    " * if your system hard disk is full, you go for adding another hard disk to store more data but you can add upto some extent.   This approach we call it as vertical scaling. This doesn't support storing of large data(tb's,pb's,etc..)\n",
    " \n",
    " * Instead of using single machine, we go for using mutliple machines by connecting them with a network\n",
    "This we call it as horizantal scaling.\n",
    "\n",
    " * We don't have any supporting application which can combine all machines in a network as single unit. So, we needed a netwrok based file system.\n",
    " \n",
    "<b> HDFS is a network based file system  or distributed file system. </b>\n",
    " \n",
    "   * Distributed\n",
    "       * Store your data as single system/unit and no need to care about data\n",
    "   * Scalable\n",
    "       * you can add n no of machines to network\n",
    "   * Cost Effective\n",
    "       * least cost machines are also supported\n",
    "   * Fault Tolerant\n",
    "       * if any failures, data won't be losed\n",
    "   * High Throughput\n",
    "       * Processing time is low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> HDFS follows master slave architecture </b>\n",
    "* Master we call it as Name node\n",
    "    * Name node will perform various checks, file already exists, has permissions to create,etc..\n",
    "    * Name node will have infomation about data nodes, it's availability,free space\n",
    "    * Name node have meta data in the form of fs image,edit log\n",
    "    * If name node doesn't receive any heart beat from data node, it treats that it's dead.\n",
    "    * Name node maintains all meta data in memory as fsimage and keeps data changes info in editlog\n",
    "    * From 2.x onwards, hadoop introduced QJM(quorum journal manager) this keeps store editlog in any of the\n",
    "    \n",
    "* Slave we call it as Data Node\n",
    "    * Data node will have data in the form of blocks\n",
    "    * Each block has default size of 128 MB\n",
    "    * If the file size exceed it's configured block size then it splits to multiple blocks\n",
    "    * Data Nodes keeps communicate with name node with heart beat whehter they are alive or dead\n",
    "    * Block size can be increased/decreased\n",
    "    * Making replication as 3 that's good for data node failures\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> What if name node fails </b>\n",
    "* There's a stand by name node that keeps storing only edit log from QJM because QJM stores backup of active name node edit log and also all the data nodes will send block report info via heart beat mechanism to stand by name node\n",
    "* There's a secondary name node which have check points of fsimage. so, if name node fails then it merges edit log from stand by node and last check point fs image and work as active name node\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YARN\n",
    "* <b> Components of Yarn </b>\n",
    "    * Resource manager (one per cluster)\n",
    "    * Node Manager (one per datanode)\n",
    "* When we submit an application(may be spark submit) , the request goes to yarn resource manager and it finds one node manager and asks to find one container and it is first container that we call it as application master.\n",
    "* Application master takes responsibility of executing that job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
